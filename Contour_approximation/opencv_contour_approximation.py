# -*- coding: utf-8 -*-
"""OpenCV Contour Approximation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FH9kbRxEUXaBIX5j9aru5EDMREQad3xs

link: https://www.pyimagesearch.com/2021/10/06/opencv-contour-approximation/#pyuni-reco-header

Ramer–Douglas–Peucker(RDP) algorithm

- for self-driving cars, if the road is so curved then smooting the curve may help self-driving car understand the obstacle better
- in this RDP algorithm, we first choose a reference point and max_point along a line and set a threshold. Then we measure the distance between ref_pont and max_point if it is less the than the threshold then we simply ignore the values less than it and repetitatively we then take max_point as ref point and measure distance between ref_pont and max_point until we eliminate the vertices along the line to smooth the curve
"""

# import the necessary packages
import numpy as np
import argparse
import imutils
import cv2
# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-i", "--image", type=str, default="Shape.png",
	help="path to input image")
args = vars(ap.parse_args())

"""- An argument parser instance is created to give the user an easy command line interface experience when they choose the image they wish to tinker with (Lines 7-10). The default image is set as shape.png, the image which already exists in the directory."""

# load the image and display it
image = cv2.imread(args["image"])
cv2.imshow("Image", image)

"""- The image provided as the argument is then read using OpenCV’s imread and displayed"""

# convert the image to grayscale and threshold it
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 200, 255,
	cv2.THRESH_BINARY_INV)[1]
cv2.imshow("Thresh", thresh)

"""- Since we’ll be using the boundary of the shape in the image, we convert the image from RGB to grayscale (Line 3). Once in grayscale format, the shape can easily be isolated using OpenCV’s threshold function
- Note that since we have chosen cv2.THRESH_BINARY_INV as the parameter on Line 4, the high-intensity pixels are changed to 0, while the surrounding low-intensity pixels become 255
"""

# find the largest contour in the threshold image
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
	cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
c = max(cnts, key=cv2.contourArea)
# draw the shape of the contour on the output image, compute the
# bounding box, and display the number of points in the contour
output = image.copy()
cv2.drawContours(output, [c], -1, (0, 255, 0), 3)
(x, y, w, h) = cv2.boundingRect(c)
text = "original, num_pts={}".format(len(c))
cv2.putText(output, text, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX,
	0.9, (0, 255, 0), 2)
# show the original contour image
print("[INFO] {}".format(text))
cv2.imshow("Original Contour", output)
cv2.waitKey(0)

"""- Using OpenCV’s findContours function, we can single out all possible contours in the given image (depending on the given arguments) . We have used the RETR_EXTERNAL argument, which only returns single representations of available contours.
- The other argument used is CHAIN_APPROX_SIMPLE. This removes many vertices in a single chain line connection, vertices that are essentially redundant.
- We then grab the largest contour from the array of contours (this contour belongs to the shape) and trace it on the original image . For this purpose, we use OpenCV’s drawContours function. We also use the putText function to write on the image.
"""

# to demonstrate the impact of contour approximation, let's loop
# over a number of epsilon sizes
for eps in np.linspace(0.001, 0.05, 10):
	# approximate the contour
	peri = cv2.arcLength(c, True)
	approx = cv2.approxPolyDP(c, eps * peri, True)
	# draw the approximated contour on the image
	output = image.copy()
	cv2.drawContours(output, [approx], -1, (0, 255, 0), 3)
	text = "eps={:.4f}, num_pts={}".format(eps, len(approx))
	cv2.putText(output, text, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX,
		0.9, (0, 255, 0), 2)
	# show the approximated contour image
	print("[INFO] {}".format(text))
	cv2.imshow("Approximated Contour", output)
	cv2.waitKey(0)

"""As mentioned earlier, we’ll need a value eps, which will act as the threshold value to measure vertices. Accordingly, we start looping epsilon’s (eps) value over a range to feed it to the contour approximation function .

the perimeter of the contour is calculated using cv2.arcLength. We then use the cv2.approxPolyDP function and initiate the contour approximation process . The eps × peri value acts as the approximation accuracy and will change with each epoch due to eps’s incremental nature.

We proceed to trace the resultant contour on the image on each epoch to assess the results .

- Notice how gradually the curves get smoother and smoother. As the threshold increases, the more linear it gets. By the time the value of eps has reached 0.0500, the contour is now a perfect rectangle, having a mere 4 points. That’s the power of the Ramer–Douglas–Peucker algorithm.
"""